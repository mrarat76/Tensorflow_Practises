{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOGbdFu3fOgyCaQmqzG6l1x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrarat76/Tensorflow_Practises/blob/main/tensor_random_practise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Düşürme (Dropout) Katmanı Örneği:\n",
        "Düşürme katmanı, aşırı uydurmayı azaltmak ve modelin genelleme yapabilmesini sağlamak için kullanılır. Her bir öğrenme adımında belirli bir olasılıkla nöronları devre dışı bırakır."
      ],
      "metadata": {
        "id": "DH7VdlAWI5HZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hePtdNf6IhCC"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),  # Düşürme katmanı, %50 olasılıkla nöronları devre dışı bırakır\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Toplama (Pooling) Katmanı Örneği:\n",
        "Toplama katmanları, evrişimli katmanlarla birlikte kullanılır ve özellik haritalarını küçültmek ve önemli özellikleri vurgulamak için kullanılır."
      ],
      "metadata": {
        "id": "rS0iNLggIvMO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2))  # MaxPooling katmanı, en büyük değeri seçerek boyutu küçültür\n",
        "])\n"
      ],
      "metadata": {
        "id": "G7Z95-FrIs_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Normalizasyon Katmanı Örneği:\n",
        "Normalizasyon katmanları, verilerin ortalamasını sıfır yapmak ve standart sapmayı bir sabit değerde tutmak için kullanılır."
      ],
      "metadata": {
        "id": "aM-X46TwI-rg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    tf.keras.layers.BatchNormalization(),  # Normalizasyon katmanı\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n"
      ],
      "metadata": {
        "id": "9LpXPELKJC6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Evrişimli (Convolutional) Katman Örneği:\n",
        "Evrişimli katmanlar, özellik haritaları çıkarmak için kullanılır ve genellikle görüntü işleme görevlerinde kullanılır."
      ],
      "metadata": {
        "id": "AvfUn_8UJFB5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n"
      ],
      "metadata": {
        "id": "bfiEyd-SJsSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tekrarlayan (Recurrent) Katman Örneği:\n",
        "Tekrarlayan katmanlar, sıralı verileri işlemek için kullanılır. Özellikle zaman serileri veya metin verileri gibi veri türleri üzerinde kullanışlıdır."
      ],
      "metadata": {
        "id": "pgD7NkdEJvTg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=10000, output_dim=32, input_length=100),\n",
        "    tf.keras.layers.LSTM(64),  # LSTM tekrarlayan katmanı\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n"
      ],
      "metadata": {
        "id": "5cwhSk_NJ0qf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"Maksimum değer\" terimi, bir veri kümesi veya belirli bir veri noktası içindeki en yüksek değeri ifade eder. Maksimum değer, veri noktalarının veya özelliklerin arasında bulunan en büyük sayıdır.\n",
        "\n",
        "Örnekler:\n",
        "\n",
        "1. **Sayılar Kümesinde Maksimum Değer:** Bir sayılar kümesinde en büyük sayı maksimum değeri temsil eder. Örneğin, 2, 5, 8, 10, ve 15 sayıları içeren bir kümede, 15 maksimum değeri temsil eder.\n",
        "\n",
        "2. **Veri Setinde Maksimum Değer:** Bir veri setindeki en yüksek veri noktası, veri setinin maksimum değeridir. Örneğin, bir sıcaklık veri setinde, bir yıl içinde en yüksek sıcaklık değeri maksimum değeri temsil eder.\n",
        "\n",
        "3. **Fonksiyon Grafiklerinde Maksimum Değer:** Bir matematiksel fonksiyonun grafiği üzerinde, bir belirli aralıkta maksimum değer, o fonksiyonun o aralıktaki en yüksek noktasını ifade eder.\n",
        "\n",
        "Maksimum değer, verileri analiz etmek, kararlar almak veya optimize etmek için önemlidir. Özellikle veri bilimi, mühendislik, istatistik ve matematik gibi alanlarda sıkça kullanılır."
      ],
      "metadata": {
        "id": "zu7qZjp1YxVp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Laplacian kernel, görüntü işleme ve işaretleme alanında yaygın olarak kullanılan bir konvolüsyonel filtre (kernel) türüdür. Bu kernel, görüntü veya işaretlerdeki kenarları ve köşeleri tespit etmek veya vurgulamak için kullanılır. Genellikle Laplacian of Gaussian (LoG) filtresi olarak da adlandırılır.\n",
        "\n",
        "Laplacian kernel, ikinci türev (gradyanın ikinci türevi) işlemine benzer bir işlemi uygular ve bir görüntü üzerindeki piksel değerlerini değiştirir. Laplacian kernel, bir pikselin çevresindeki piksellerin farklarını hesaplar ve sonucu kullanarak o pikselin etrafındaki yoğunluk değişikliklerini ölçer. Bu, kenarların ve köşelerin tespit edilmesini sağlar çünkü bu bölgelerde yoğunluk değişiklikleri daha yüksektir.\n",
        "\n",
        "Laplacian kernel, genellikle Gauss filtresi ile önceden yumuşatma yapılarak kullanılır. Yumuşatma işlemi, gürültüyü azaltmak ve filtrelemenin daha iyi sonuçlar vermesini sağlamak için uygulanır. Laplacian of Gaussian (LoG) filtresi, görüntü işleme uygulamalarında özellik çıkarma ve kenar tespiti gibi çeşitli işlemlerde kullanılır.\n",
        "\n",
        "Laplacian kernel, aşağıdaki gibi bir matris şeklinde temsil edilebilir:\n",
        "\n",
        "```\n",
        "  0  -1   0\n",
        " -1   4  -1\n",
        "  0  -1   0\n",
        "```\n",
        "\n",
        "Bu matris, Laplacian işlemini uygularken her pikselin çevresindeki komşu piksellerin değerleri ile çarpılır ve sonuç, o pikselin yeni değerini oluşturur.\n",
        "\n",
        "Laplacian kernel, özellikle görüntü işleme uygulamalarında kullanılan güçlü bir araçtır ve kenar tespiti, görüntü iyileştirme ve özellik çıkarma gibi birçok görevde kullanılır."
      ],
      "metadata": {
        "id": "XtAa_BxUY1Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1. **POOL Katmanları Nedir?**\n",
        "   POOL katmanları, bir CNN'deki önemli bir bileşenidir ve giriş verisinin boyutunu küçültmek ve önemli özellikleri vurgulamak için kullanılırlar. Bu katmanlar, veri boyutunu azaltarak hesaplama yükünü azaltır ve aynı zamanda ağın belirli özelliklere odaklanmasına yardımcı olur.\n",
        "\n",
        "2. **Receptive Field Size (Alıcı Alan Boyutu) ve Stride (Adım):**\n",
        "   POOL katmanları, iki ana parametreye sahiptir. İlk olarak, \"receptive field size\" veya \"pool size\" olarak adlandırılan F (genellikle 2x2 veya 3x3 gibi bir matris) belirlenir. İkincisi, \"stride\" olarak adlandırılan S belirlenir. Stride, her bir POOL işlemi sonrasında ne kadar kaydırma yapılacağını belirler.\n",
        "\n",
        "3. **POOL İşlemi ve Çıkış Boyutu:**\n",
        "   POOL işlemi, her bir FxF boyutundaki bölge içindeki değerler arasından en büyük değeri seçmek şeklinde çalışır. Ardından, bir adım (stride) boyunca kaydırma yapılır ve işlem tekrar uygulanır. Sonuç olarak, giriş boyutunu küçültür ve çıkış boyutunu hesaplar.\n",
        "\n",
        "4. **Çıkış Boyutunun Hesaplanması:**\n",
        "   Çıkış boyutu (Woutput, Houtput, Doutput), giriş boyutu (Winput, Hinput, Dinput), receptive field boyutu (F) ve stride (S) parametreleri kullanılarak hesaplanır:\n",
        "   \n",
        "   - Woutput = ((Winput - F) / S) + 1\n",
        "   - Houtput = ((Hinput - F) / S) + 1\n",
        "   - Doutput = Dinput\n",
        "\n",
        "5. **Pooling Türleri:**\n",
        "   Metinde iki yaygın POOL türü belirtilmiştir:\n",
        "   - Tip #1: F = 3, S = 2, bu tip \"overlap pooling\" olarak adlandırılır ve genellikle büyük spatial boyutlara sahip görüntülerde veya giriş verilerinde kullanılır.\n",
        "   - Tip #2: F = 2, S = 2, bu tip \"non-overlapping pooling\" olarak adlandırılır ve daha küçük spatial boyutlara sahip görüntülerde veya giriş verilerinde yaygın olarak kullanılır. Ayrıca, küçük giriş verileri (örneğin, 32-64 piksel) için F = 2, S = 1 de kullanılabilir.\n",
        "\n",
        "6. **POOL vs. CONV:**\n",
        "   Bazı çalışmalarda, POOL katmanlarının kullanılması yerine sadece CONV (evrişimli) katmanlarının daha büyük stride ile verinin boyutunu küçültmek için kullanılması önerilmektedir. Özellikle Convolutional Neural Network (CNN) modellerinde bu yaklaşımın performanslı olduğu gösterilmiştir. Ancak bazı durumlarda son katmanda sadece average pooling kullanılarak sonlandırılabilir.\n",
        "\n",
        "Sonuç olarak, POOL katmanları görüntü işleme ve CNN modellerinde veri boyutunu küçültmek ve önemli özellikleri vurgulamak için kullanılan önemli bir bileşen olarak kabul edilir. Bununla birlikte, bazı modern ağ mimarilerinde sadece CONV katmanları ve büyük stride kullanarak da başarılı sonuçlar elde edilebilir."
      ],
      "metadata": {
        "id": "5Qy_Idt5Y9nn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##SCCE & CCE\n",
        "\n",
        "\n",
        "**Sparse categorical cross entropy (SCCE) ve categorical cross entropy (CCE), ikisi de sınıflandırma problemlerinde kullanılan kayıp fonksiyonlarıdır. Ancak bunlar arasında önemli farklar vardır.**\n",
        "\n",
        "**Hedef Biçimi:**\n",
        "\n",
        "CCE: Bu yöntemde, hedeflerin her biri bir vektör olarak temsil edilir. Örneğin, bir veri noktasının hedefi \"köpek\" ise, vektör [0, 1, 0] gibi olabilir, burada sadece \"köpek\" sınıfının indeksi 1 olarak temsil edilir.\n",
        "SCCE: Burada hedefler sınıf endeksleri olarak temsil edilir. Yani, bir veri noktasının hedefi \"köpek\" ise, sadece \"köpek\" sınıfının indeksi 1 olarak temsil edilir.\n",
        "\n",
        "**Kullanım Alanları:**\n",
        "\n",
        "**CCE**: Kategorik (one-hot encoded) hedeflerle kullanılır. Yani, çıktılarınız softmax aktivasyonuna sahip bir nöral ağ kullanıyorsanız ve her veri noktasının yalnızca bir sınıfa ait olduğunu biliyorsanız, CCE kullanmak uygun olacaktır.\n",
        "**SCCE**: Sınıf endeksleri ile kullanılır. Eğer hedefler one-hot encoded değilse, yani her veri noktasının yalnızca bir sınıfa ait olduğunu bilmiyorsanız, SCCE kullanmak daha uygundur. Örneğin, çoklu sınıf etiketleri içeren bir veri kümesiyle çalışıyorsanız, SCCE kullanmak daha uygun olabilir.\n",
        "Performans ve Hesaplama:\n",
        "\n",
        "CCE ve SCCE'nin performansı birbirine oldukça yakındır, ancak kullanım senaryonuza bağlı olarak biri diğerinden daha uygun olabilir.\n",
        "CCE'nin hesaplama açısından daha yoğun olabileceği durumlar vardır, çünkü one-hot encoded vektörlerin hesaplanması gerekebilir. Bununla birlikte, SCCE daha az bellek gerektirir çünkü hedefler doğrudan sınıf endeksleri olarak temsil edilir.\n",
        "Bu farklar, hangi kayıp fonksiyonunun hangi senaryoda daha uygun olduğunu belirlemenize yardımcı olabilir.\n"
      ],
      "metadata": {
        "id": "68Vhwz5zvOYL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Ağırlıklar ve Ön Yargılar (Weights and Biases)**\n",
        "\n",
        "##**Weight (Ağırlık):**\n",
        "\n",
        "**Görevi**: Ağırlıklar, yapay sinir ağlarında bağlantıların gücünü belirler. Bu bağlantılar, bir sinir ağındaki farklı katmanlardaki sinirler arasındaki ilişkiyi temsil eder.\n",
        "\n",
        "**Parametre**: Bir ağırlık, sinir ağındaki her bir bağlantı için bir parametredir. Her bir bağlantı, iki sinir arasındaki bağlantıyı temsil eder.\n",
        "\n",
        "**İşlevi**: Bir sinirin girdi verilerini alırken, bu verileri işlerken ve çıktı üretirken ağırlıklar kullanılır. Ağırlıklar, girdi verilerinin sinirler arasında nasıl aktarılacağını belirler.\n",
        "\n",
        "**Eğitim**: Ağırlıklar, eğitim sırasında verilen örneklerle uyumlu hale getirilir. Bu genellikle bir optimizasyon algoritması (örneğin, geri yayılım) kullanılarak gerçekleştirilir.\n",
        "\n",
        "##**Bias (Önyargı):**\n",
        "\n",
        "**Görevi**: Önyargılar, sinir ağında bir sinirin aktivasyonunu ne kadar kolayca başlatmasına izin veren ek bir terimdir. Aktivasyon eşiğini ayarlar.\n",
        "\n",
        "**Parametre**: Bir sinir için bir önyargı parametresi vardır. Her bir sinirin kendine özgü bir önyargısı bulunur.\n",
        "\n",
        "**İşlevi**: Önyargılar, sinir ağının daha esnek olmasını sağlar. Örneğin, bir sinirin girdi toplamı artı önyargı, belirli bir eşiği aşarsa, sinir aktive olur.\n",
        "\n",
        "**Eğitim**: Önyargılar da eğitim sırasında ayarlanır. Diğer parametreler gibi, verilen örneklerle uyumlu hale getirilirler. Bu, modelin verilere daha iyi uymasını sağlar.\n",
        "\n",
        "\n",
        "## **Aktivasyon Eşiği (Threshold)**\n",
        "\n",
        "Aktivasyon eşiği (threshold), bir sinirin ne zaman aktive olacağını belirleyen bir kavramdır. Yapay sinir ağlarında, bir sinirin aktivasyonu, girdi sinyallerinin ağırlıklı toplamının (weighted sum) belirli bir eşiği aşmasıyla gerçekleşir.\n",
        "\n",
        "Bir sinir, girdi sinyallerini alır, bu girdileri belirli ağırlıklarla çarpar ve bu ağırlıklı toplamı hesaplar. Daha sonra, bu ağırlıklı toplama bir önyargı (bias) eklenir. Sonuç, aktivasyon fonksiyonuna (activation function) tabi tutulur. Aktivasyon fonksiyonu, bu toplamın belirli bir eşiği aşması durumunda sinirin aktive olup olmayacağını belirler.\n",
        "\n",
        "Eğer ağırlıklı toplam ve önyargının toplamı, belirlenen aktivasyon eşiğinden büyük veya eşitse, sinir aktive olur ve çıktı üretir. Aksi takdirde, sinir aktive olmaz ve çıktı üretmez.\n",
        "\n",
        "Bu mekanizma, sinir ağlarının belirli bir uyarım düzeyini aşan girdilere tepki vermesini sağlar ve böylece sinir ağlarının karmaşık işlevleri öğrenmesine ve uygulamasına olanak tanır.\n",
        "\n",
        "\n",
        "\n",
        "##Weighted Sum\n",
        "\n",
        "Ağırlıklı toplam (weighted sum), bir sinirin girdi sinyallerinin ağırlıklarla çarpılıp toplanmasıdır. Yapay sinir ağlarında, bir sinirin bir önceki katmandaki tüm sinirlerden gelen girdi sinyallerini toplamak için kullanılır.\n",
        "\n",
        "Bir sinirin ağırlıklı toplamını hesaplamak için, her girdi sinyali, sinire gelen bağlantının ağırlığı ile çarpılır. Bu çarpımların toplamı alınır ve sonuç, sinirin ağırlıklı toplamıdır.\n",
        "\n",
        "\n",
        "Bu işlem, bir sinirin girdi sinyallerini ve bu girdilerin sinirin çıktısını belirlemekte ne kadar etkili olacağını belirler. Özellikle, ağırlıklar eğitim sırasında öğrenilir ve bu sayede sinir ağı belirli bir görevi daha iyi yapabilir hale gelir. Önyargı terimi de sinirin aktivasyon eşiğini belirleyerek, sinirin aktive olma veya aktive olmama kararını etkiler.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xCcCm7Ipar4R"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ezuh1eO6v8Yf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Computer Vision**\n"
      ],
      "metadata": {
        "id": "suN_jY4E_NDd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conv2D (Convolutional Layer)**:\n",
        "\n",
        "Giriş görüntüsünde filtreleme işlemi gerçekleştirir.\n",
        "Filtreler, giriş görüntüsündeki özellikleri vurgulamak veya algılamak için kullanılır.\n",
        "Her filtre, belirli bir özellik veya deseni algılar ve giriş görüntüsü üzerinde kaydırarak bu özellikleri tespit eder.\n",
        "Örneğin, kenar tespiti, köşe tespiti veya diğer daha yüksek seviye özelliklerin algılanması için kullanılabilir.\n",
        "\n",
        "**MaxPool2D (Max Pooling Layer)**:\n",
        "\n",
        "Giriş görüntüsünü küçültmek ve önemli özellikleri vurgulamak için kullanılır.\n",
        "Genellikle hesaplama yükünü azaltmak ve özelliklerin translasyonel özelliğini sağlamak için kullanılır.\n",
        "Bir bölgeyi alır ve bu bölgenin maksimum değerini çıkararak giriş görüntüsünü küçültür.\n",
        "Genellikle bir Conv2D katmanının ardından kullanılır ve özellik haritalarını küçültmek için kullanılır.\n",
        "\n",
        "Kısacası, Conv2D katmanı giriş görüntüsündeki özellikleri algılar ve vurgularken, MaxPool2D katmanı bu özellik haritalarını küçültür ve önemli özellikleri vurgular. Bu iki katman, genellikle birlikte kullanılarak derin öğrenme modellerinin özellik çıkarımını gerçekleştirir.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SDnO1sr4_S9_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MaxPooling, yaygın olarak Convolutional Neural Networks (CNNs) gibi derin öğrenme mimarilerinde kullanılan bir katman türüdür. Bu katmanın temel amacı, giriş olarak aldığı özellik haritasını (feature map) küçültmek ve aynı zamanda önemli özellikleri vurgulamaktır.\n",
        "\n",
        "MaxPooling katmanı genellikle bir Convolutional Neural Network (CNN)'nin ardından gelir. Özellik haritasının boyutunu azaltmak için kullanılır. Genellikle, her bir bölgenin (genellikle 2x2 veya 3x3 bir pencere) maksimum değerini alarak çalışır. Bu işlem, özellik haritasını örneğin yarıya indirir.\n",
        "\n",
        "İşlevsel olarak, MaxPooling katmanı, ağın translasyonel invariyansını artırır. Yani, özellik haritasındaki bir nesnenin farklı konumlarını göz önüne almadan, aynı nesneyi tanıma yeteneğini artırır. Ayrıca, hesaplama maliyetini azaltır ve modelin daha hızlı eğitilmesine veya tahmin yapmasına olanak tanır.\n",
        "\n",
        "MaxPooling katmanı şu şekilde çalışır:\n",
        "\n",
        "Giriş olarak aldığı özellik haritası üzerinde bir kaydırıcı (sliding window) kullanır.\n",
        "Her bir pencerenin maksimum değerini alır ve yeni bir özellik haritası oluşturur.\n",
        "Bu işlem özellik haritasını küçültürken, önemli özellikleri vurgular.\n",
        "Özetle, MaxPooling katmanı, özellik haritasını küçülterek hesaplama maliyetini azaltır, önemli özellikleri vurgular ve ağın translasyonel invariyansını artırır. Bu nedenle, derin öğrenme modellerinin önemli bir bileşeni olarak yaygın bir şekilde kullanılır."
      ],
      "metadata": {
        "id": "yCPv3vaXDEPW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dense (Fully Connected) Katmanı**:\n",
        "\n",
        "Her bir çıkış nöronunun tüm girişlere bağlı olduğu klasik bir sinir ağı katmanıdır.\n",
        "Giriş vektörünü alır ve çıktıyı üretmek için ağırlıklarla çarparak ve bir aktivasyon fonksiyonu uygulayarak işler.\n",
        "\n",
        "**Dropout Katmanı**:\n",
        "\n",
        "Overfitting'i azaltmak için kullanılan bir düzenleme tekniğidir.\n",
        "Rastgele bir şekilde seçilen nöronları devre dışı bırakarak, ağın genel olarak daha az bağımlı hale gelmesini sağlar.\n",
        "\n",
        "**BatchNormalization Katmanı**:\n",
        "\n",
        "Eğitim sürecini hızlandırmak ve daha iyi sonuçlar elde etmek için kullanılan bir tekniktir.\n",
        "Her bir mini-batch'in girişlerini normalize eder, böylece eğitim süreci daha hızlı ilerler.\n",
        "\n",
        "**Flatten Katmanı**:\n",
        "\n",
        "2B veya 3B tensörlerden oluşan bir girişi, tam bağlı bir sinir ağı katmanı için uygun olan tek boyutlu bir tensöre dönüştürür.\n",
        "\n",
        "**Activation (Aktivasyon) Katmanı**:\n",
        "\n",
        "Sinir ağı katmanlarının çıktılarını uyguladığı aktivasyon fonksiyonunu içerir.\n",
        "Sigmoid, ReLU, tanh gibi yaygın aktivasyon fonksiyonları kullanılabilir.\n",
        "GlobalAveragePooling2D Katmanı:\n",
        "\n",
        "Giriş özellik haritasını küçültmek ve sonuçları düzleştirmek için kullanılır.\n",
        "Ortalama alarak giriş özellik haritasının her kanalı için tek bir değer elde eder.\n"
      ],
      "metadata": {
        "id": "OD8t0aKe_e_q"
      }
    }
  ]
}